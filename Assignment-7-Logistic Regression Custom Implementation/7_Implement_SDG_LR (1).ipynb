{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "L8W2fg1cyGdX",
    "outputId": "9faaa00d-dce3-42c5-9072-286b7d3c758a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gONY1YiDq7jD"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "0DR_YMBsyOci",
    "outputId": "2630b890-edbe-4d3e-80a7-5395a0ea3ccd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "3HpvTwDHyQQy",
    "outputId": "3e0dd4cb-6188-4ab4-fcd6-97873ebf676a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "YYaVyQ2lyXcr",
    "outputId": "5c33dd0d-6f76-4242-829f-2ecea5a3ae82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.14 seconds.\n",
      "Convergence after 10 epochs took 0.14 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "EAfkVI6GyaRO",
    "outputId": "e33cd807-2e3d-4849-c23f-7cf701778527"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='green'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='green'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='green'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='green'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0Unf4Rmwl3MH"
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    w = np.zeros_like(dim)\n",
    "    b=0\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "A7I6uWBRsKc4",
    "outputId": "b44b7301-4d62-46e4-fd2f-fc162d910253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Pv1llH429wG5",
    "outputId": "5948f37f-cdf7-43cf-a86e-69a0a66c5f47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    sigmoid = 1 / (1 + math.exp(-z))\n",
    "\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ClSmygcZmL-y",
    "outputId": "6f0e5196-b0ea-4dc8-a362-737d77924e94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "P_JASp_NAfK_",
    "outputId": "f00b1aa7-55ae-4332-c99c-9ea67655af54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    s = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(0,n):\n",
    "      s = s + ( (y_true[i]*math.log10(y_pred[i])) + (1-y_true[i])*math.log10(1-y_pred[i]) )\n",
    "    loss = -1 * (1/n)*s\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "LzttjvBFCuQ5",
    "outputId": "33b9ca3a-3b87-4396-8414-2081a15a2731"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "  loss=logloss(true,pred)\n",
    "  assert(loss==0.07644900402910389)\n",
    "  return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "\n",
    "    dw =x*(y-sigmoid(np.dot(w.T,x)+b)) - ((alpha*w.T)/N)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "kWnvc76lqSb9",
    "outputId": "7edf63ad-a348-4db3-cd3f-e751362aa403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(w.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "WI3xD8ctGEnJ",
    "outputId": "46295383-2460-47aa-b798-2bcebb818962"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.sum(grad_dw)==2.613689585)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "     '''In this function, we will compute gradient w.r.to b '''\n",
    "     db = y - sigmoid(np.dot(w.T,x)+b)\n",
    "     return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "TfFDKmscG5qZ",
    "outputId": "0c550405-ec6e-4adc-b84e-31d25eeedbc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "dmAdc5ejEZ25"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    #Here eta0 is learning rate\n",
    "    #implement the code as follows\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    # for every epoch\n",
    "        # for every data point(X_train,y_train)\n",
    "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "           #compute gradient w.r.to b (call the gradient_db() function)\n",
    "           #update w, b\n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the train loss values in a list\n",
    "        # predict the output of x_test[for all data points in X_test] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the test loss values in a list\n",
    "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    tr_loss=[]\n",
    "    te_loss=[]\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "      for i in range(0,len(X_train)):\n",
    "        w = w + eta0*gradient_dw(X_train[i],y_train[i],w,b,alpha,len(X_train))\n",
    "        b = b + eta0*gradient_db(X_train[i],y_train[i],w,b)\n",
    "      y_pred =[]\n",
    "      for x in X_train:\n",
    "        y_pred.append(sigmoid(np.dot(w,x)+b))\n",
    "      tr_loss.append(logloss(y_train,y_pred))\n",
    "      y_pred =[]\n",
    "      for x in X_test:\n",
    "        y_pred.append(sigmoid(np.dot(w,x)+b))\n",
    "      te_loss.append(logloss(y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "    return w,b,tr_loss,te_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "sUquz7LFEZ6E",
    "outputId": "db6ef350-3a59-454e-bfb1-dad5a3f29af7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [01:34<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=50\n",
    "w,b,tr_loss,te_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "lLHJtiJ55XuM",
    "outputId": "b9c5e1f7-7fbe-46b0-cb3e-ce115a6046e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.29755932e-01,  1.93023807e-01, -1.48464457e-01,  3.38103415e-01,\n",
       "       -2.21228940e-01,  5.69932597e-01, -4.45183638e-01, -8.99209785e-02,\n",
       "        2.21804834e-01,  1.73809448e-01,  1.98727704e-01, -5.59450918e-04,\n",
       "       -8.13106259e-02,  3.39094296e-01,  2.29784893e-02])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ancH20Z_5eDx",
    "outputId": "1f4cf14e-a502-467f-f508-746da59bbfbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8918925964701089"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nx8Rs9rfEZ1R",
    "outputId": "e4be7a8a-6c88-4ae7-8645-cfdb93e5179a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00638902,  0.00754815,  0.0001259 , -0.00334065, -0.01304224,\n",
       "          0.00976681,  0.00724119,  0.00416715,  0.01253163, -0.00703181,\n",
       "          0.0016758 , -0.00477861, -0.00170693,  0.00056628,  0.00031128]]),\n",
       " array([-0.0387543]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "zasvNmiJBVlF",
    "outputId": "2b18d7d8-0132-451a-b7fe-b3c4fbd355e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17546926223702297,\n",
       " 0.16868174436540095,\n",
       " 0.16639953379688238,\n",
       " 0.16537404901928135,\n",
       " 0.16486122004082515,\n",
       " 0.16459114506307687,\n",
       " 0.16444479874475598,\n",
       " 0.16436411522525887,\n",
       " 0.1643191231082826,\n",
       " 0.1642938291559779,\n",
       " 0.16427952013540825,\n",
       " 0.16427138331585087,\n",
       " 0.16426673469647732,\n",
       " 0.1642640668101489,\n",
       " 0.16426252835733005,\n",
       " 0.16426163646238584,\n",
       " 0.1642611161883861,\n",
       " 0.16426081044856242,\n",
       " 0.16426062918210865,\n",
       " 0.16426052056735863,\n",
       " 0.16426045466349845,\n",
       " 0.16426041408844066,\n",
       " 0.1642603886924852,\n",
       " 0.1642603725071067,\n",
       " 0.16426036199220195,\n",
       " 0.1642603550261018,\n",
       " 0.16426035032139918,\n",
       " 0.16426034708556284,\n",
       " 0.16426034482265406,\n",
       " 0.16426034321669902,\n",
       " 0.16426034206250442,\n",
       " 0.16426034122417682,\n",
       " 0.16426034060998718,\n",
       " 0.16426034015685814,\n",
       " 0.16426033982070054,\n",
       " 0.16426033957023392,\n",
       " 0.1642603393829793,\n",
       " 0.16426033924262076,\n",
       " 0.16426033913719898,\n",
       " 0.16426033905789483,\n",
       " 0.16426033899817297,\n",
       " 0.1642603389531533,\n",
       " 0.16426033891919317,\n",
       " 0.1642603388935659,\n",
       " 0.16426033887421562,\n",
       " 0.16426033885960006,\n",
       " 0.16426033884856042,\n",
       " 0.16426033884022173,\n",
       " 0.16426033883392135,\n",
       " 0.16426033882915692]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "EuE2nEV0Bdxr",
    "outputId": "4563bdb5-a55d-4445-a66a-b29eaca85b11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1759668786191598,\n",
       " 0.16940989611779378,\n",
       " 0.16721415304424353,\n",
       " 0.16622329469756567,\n",
       " 0.16572403546384085,\n",
       " 0.16545876819806699,\n",
       " 0.16531365222077019,\n",
       " 0.16523283564551472,\n",
       " 0.1651872786451111,\n",
       " 0.16516136116063063,\n",
       " 0.165146502653406,\n",
       " 0.16513792321047355,\n",
       " 0.16513293346948432,\n",
       " 0.1651300087564692,\n",
       " 0.16512827929561427,\n",
       " 0.16512724616938745,\n",
       " 0.16512662167682646,\n",
       " 0.16512623900834086,\n",
       " 0.16512600086609153,\n",
       " 0.1651258501056387,\n",
       " 0.1651257528922146,\n",
       " 0.16512568899882157,\n",
       " 0.16512564619492068,\n",
       " 0.16512561698614076,\n",
       " 0.16512559670985402,\n",
       " 0.1651255824156623,\n",
       " 0.16512557220222615,\n",
       " 0.16512556482072047,\n",
       " 0.16512555943510132,\n",
       " 0.16512555547524393,\n",
       " 0.165125552545619,\n",
       " 0.16512555036754414,\n",
       " 0.1651255487419863,\n",
       " 0.16512554752515896,\n",
       " 0.16512554661218476,\n",
       " 0.1651255459259709,\n",
       " 0.16512554540949317,\n",
       " 0.16512554502035995,\n",
       " 0.16512554472694344,\n",
       " 0.16512554450556408,\n",
       " 0.1651255443384607,\n",
       " 0.16512554421227985,\n",
       " 0.16512554411697833,\n",
       " 0.16512554404498142,\n",
       " 0.16512554399058435,\n",
       " 0.16512554394947904,\n",
       " 0.1651255439184143,\n",
       " 0.16512554389493753,\n",
       " 0.1651255438771939,\n",
       " 0.16512554386378192]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "1O6GrRt7UeCJ",
    "outputId": "fda2f217-d2f0-43ac-fac8-ca495a1a4b5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Epochs vs Loss Value')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ep=np.arange(1,epochs+1)\n",
    "plt.plot(ep,tr_loss)\n",
    "plt.plot(ep,te_loss)\n",
    "plt.legend(['Train loss','Test loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.title('Epochs vs Loss Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "FUN8puFoEZtU",
    "outputId": "cdba4dd4-b8f9-4ca0-f06c-7aaa43327de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95224\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k28U1xDsLIO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMokBfs3-2PY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7_Implement_SDG_LR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
