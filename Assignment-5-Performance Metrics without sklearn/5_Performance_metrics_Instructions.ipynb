{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_confusion_matrix(df,a,b):\n",
    "\n",
    "    true_positive= ((df[a]==1.0)&(df[b]==1.0)).sum()\n",
    "    true_negative= ((df[a]==0.0)&(df[b]==0.0)).sum()\n",
    "    false_negative=((df[a]==1.0)&(df[b]==0.0)).sum()\n",
    "    false_positive=((df[a]==0.0)&(df[b]==1.0)).sum()\n",
    "                \n",
    "    return true_negative,false_negative,false_positive,true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "df_a = pd.read_csv(\"C:\\\\Users\\\\Akashraj D S\\\\Downloads\\\\5_Performance_metrics\\\\5_a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_a['proba']=df_a['proba'].apply(lambda row: round(row,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a['y_pred']=df_a.apply(lambda row: 0.0 if row.proba<0.5 else 1.0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative,false_negative,false_positive,true_positive=find_confusion_matrix(df_a,'y','y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confusion_matrix=np.array([[true_negative,false_positive],\n",
    "                           [false_negative,true_positive]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   100]\n",
      " [    0 10000]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is 0.99 and Recall is 1.00\n",
      "f1-score is 1.00\n"
     ]
    }
   ],
   "source": [
    "#precision is predicted positives\n",
    "precision = true_positive/(true_positive + false_positive)\n",
    "#recall is actual positives\n",
    "recall = true_positive/(true_positive + false_negative)\n",
    "print(\"Precision is {0:.2f} and Recall is {1:.2f}\".format(precision,recall))\n",
    "f1_score = 2 * ((precision*recall)/(precision+recall))\n",
    "print(\"f1-score is {:.2f}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df_a.sort_values(by='proba',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899965</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899812</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899768</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y     proba  y_pred\n",
       "1664  1.0  0.899965     1.0\n",
       "2099  1.0  0.899828     1.0\n",
       "1028  1.0  0.899825     1.0\n",
       "9592  1.0  0.899812     1.0\n",
       "8324  1.0  0.899768     1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10100/10100 [00:40<00:00, 250.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score is 0.49 and accuracy is 0.99\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "y_as_0 = len(df_a[df_a['y']==0.0])\n",
    "y_as_1 = len(df_a[df_a['y']==1.0])\n",
    "tpr=[]\n",
    "fpr=[]\n",
    "for i in tqdm(df_a['proba'].unique()):\n",
    "    df_a['y_p']=np.where(df_a['proba']>=i,1,0)\n",
    "    TP = ((df_a['y']==1.0) & (df_a['y_p'] == 1.0)).sum()\n",
    "    FP=  ((df_a['y']==0.0) & (df_a['y_p'] == 1.0)).sum()\n",
    "    tpr.append(TP/y_as_1)\n",
    "    fpr.append(FP/y_as_0)\n",
    "    \n",
    "AUC = np.trapz(tpr,fpr)\n",
    "accuracy = (true_positive + true_negative)/(true_negative + false_negative + false_positive + true_positive) \n",
    "print('AUC Score is {0:.2f} and accuracy is {1:.2f}'.format(AUC,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [],
   "source": [
    "# write your code\n",
    "df_b = pd.read_csv(\"C:\\\\Users\\\\Akashraj D S\\\\Downloads\\\\5_Performance_metrics\\\\5_b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_b['proba']=df_b['proba'].apply(lambda row: round(row,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b['y_pred']=df_b.apply(lambda row: 0.0 if row.proba<0.5 else 1.0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b=df_b.sort_values(by='proba',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative,false_negative,false_positive,true_positive=find_confusion_matrix(df_b,'y','y_pred')\n",
    "confusion_matrix=np.array([[true_negative,false_positive],\n",
    "                           [false_negative,true_positive]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9761  239]\n",
      " [  45   55]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is 0.1870748299319728 and Recall is 0.55\n",
      "f1-score is 0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "#precision is predicted positives\n",
    "precision = true_positive/(true_positive + false_positive)\n",
    "\n",
    "#recall is actual positives\n",
    "recall = true_positive/(true_positive + false_negative)\n",
    "print(\"Precision is {0} and Recall is {1}\".format(precision,recall))\n",
    "\n",
    "f1_score = 2 * ((precision*recall)/(precision+recall))\n",
    "print(\"f1-score is {}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10100/10100 [00:39<00:00, 253.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score is 0.9377570000000001 and accuracy is 0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "y_as_0 = (df_b['y']==0.0).sum()\n",
    "y_as_1 = (df_b['y']==1.0).sum()\n",
    "tpr=[]\n",
    "fpr=[]\n",
    "for i in tqdm(df_b['proba'].unique()):\n",
    "    df_b['y_p']=np.where(df_b['proba']>=i,1,0)\n",
    "    TP = ((df_b['y']==1.0) & (df_b['y_p'] == 1.0)).sum()\n",
    "    FP=  ((df_b['y']==0.0) & (df_b['y_p'] == 1.0)).sum()\n",
    "    tpr.append(TP/y_as_1)\n",
    "    fpr.append(FP/y_as_0)\n",
    "AUC = np.trapz(tpr,fpr)\n",
    "accuracy = (true_positive + true_negative)/(true_negative + false_negative + false_positive + true_positive) \n",
    "print('AUC Score is {0} and accuracy is {1}'.format(AUC,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [],
   "source": [
    "# write your code\n",
    "df_c = pd.read_csv(\"C:\\\\Users\\\\Akashraj D S\\\\Downloads\\\\5_Performance_metrics\\\\5_c.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.418652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y      prob\n",
       "0  0  0.458521\n",
       "1  0  0.505037\n",
       "2  0  0.418652\n",
       "3  0  0.412057\n",
       "4  0  0.375579"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.sort_values(by='prob',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2791/2791 [00:10<00:00, 266.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The threshold with minimum A value is 0.2300390278970873\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "y_as_0 = (df_b['y']==0.0).sum()\n",
    "y_as_1 = (df_b['y']==1.0).sum()\n",
    "total_val=[]\n",
    "for i in tqdm(df_c['prob'].unique()):\n",
    "    df_c['y_p']=np.where(df_c['prob']>=i,1,0)\n",
    "    FP=  ((df_c['y']==0.0) & (df_c['y_p'] == 1.0)).sum()\n",
    "    FN=  ((df_c['y']==1.0) & (df_c['y_p'] == 0.0)).sum()\n",
    "    total_val.append(500*FN + 100*FP)\n",
    "    \n",
    "d=dict(zip(df_c['prob'].unique(),total_val))\n",
    "print(\"The threshold with minimum A value is {0}\".format([key for key in d if d[key] == min(d.values())][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
    "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = pd.read_csv(\"C:\\\\Users\\\\Akashraj D S\\\\Downloads\\\\5_Performance_metrics\\\\5_d.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   pred\n",
       "0  101.0  100.0\n",
       "1  120.0  100.0\n",
       "2  131.0  113.0\n",
       "3  164.0  125.0\n",
       "4  154.0  152.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d['SSE']=(df_d['y']-df_d['pred'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value_of_y = df_d['y'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d['SST']=(df_d['y']-mean_value_of_y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "      <th>SSE</th>\n",
       "      <th>SST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1185.969885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2855.610598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>4152.244694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>9494.146985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7645.388715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   pred     SSE          SST\n",
       "0  101.0  100.0     1.0  1185.969885\n",
       "1  120.0  100.0   400.0  2855.610598\n",
       "2  131.0  113.0   324.0  4152.244694\n",
       "3  164.0  125.0  1521.0  9494.146985\n",
       "4  154.0  152.0     4.0  7645.388715"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SQUARED ERROR : 177.16569974554707\n",
      "MAPE Value is 0.12912029940096867\n",
      "r-square score is 0.9563582786990964\n"
     ]
    }
   ],
   "source": [
    "print('MEAN SQUARED ERROR : {}'.format(df_d['SSE'].sum()/len(df_d)))\n",
    "df_d['MAPE_VALUES']=np.absolute((df_d['SSE']**0.5)/df_d['y'].mean())\n",
    "print('MAPE Value is {}'.format(df_d['MAPE_VALUES'].sum()/len(df_d)))\n",
    "print('r-square score is {}'.format(1-(df_d['SSE'].mean()/df_d['SST'].mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
